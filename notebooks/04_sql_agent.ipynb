{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d93b9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run whole script\n",
    "%run 03_safe_execution.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8cd6f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd4baa3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09dc97d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path(\"D:/code/text-to-sql-agent\")))\n",
    "# from src.db.db_connection import get_db_connection\n",
    "\n",
    "# conn = get_db_connection()\n",
    "# cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baad3df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['tables', 'hints', 'common_joins'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------------------------------------------\n",
    "# Load enriched schema (semantics + joins)\n",
    "# -------------------------------------------------------\n",
    "\n",
    "SCHEMA_PATH = Path(\"../src/schema/schema_summary.yaml\")\n",
    "\n",
    "with open(SCHEMA_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    schema_context: Dict[str, Any] = yaml.safe_load(f)\n",
    "\n",
    "schema_context.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3471b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------\n",
    "# Optimized SQL generation prompt\n",
    "# -------------------------------------------------------\n",
    "\n",
    "def build_optimized_prompt(\n",
    "    question: str,\n",
    "    schema: Dict[str, Any]\n",
    ") -> str:\n",
    "    return f\"\"\"\n",
    "You are an expert PostgreSQL SQL generator.\n",
    "\n",
    "CRITICAL RULES:\n",
    "- Output ONLY one SQL SELECT query\n",
    "- Do NOT include markdown, backticks, or explanations\n",
    "- Use ONLY tables and columns from the schema\n",
    "- Follow join templates strictly\n",
    "- Never invent joins or columns\n",
    "- Prefer correctness over brevity\n",
    "\n",
    "Database schema with semantics:\n",
    "{schema}\n",
    "\n",
    "User question:\n",
    "{question}\n",
    "\n",
    "SQL:\n",
    "\"\"\".strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d21190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "def load_llm():\n",
    "    return ChatOpenAI(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        temperature=0,\n",
    "        openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "442ab63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------\n",
    "# LLM call using ChatOpenAI\n",
    "# -------------------------------------------------------\n",
    "\n",
    "def call_llm(prompt: str) -> str:\n",
    "    llm = load_llm()\n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2e5439d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------\n",
    "# Generate SQL (optimized)\n",
    "# -------------------------------------------------------\n",
    "\n",
    "def generate_sql_optimized(question: str) -> str:\n",
    "    prompt = build_optimized_prompt(question, schema_context)\n",
    "    raw_sql = call_llm(prompt)\n",
    "    return raw_sql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50473e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------\n",
    "# Optimized correction prompt\n",
    "# -------------------------------------------------------\n",
    "\n",
    "def build_optimized_correction_prompt(\n",
    "    question: str,\n",
    "    schema: Dict[str, Any],\n",
    "    previous_sql: str,\n",
    "    error_reason: str\n",
    ") -> str:\n",
    "    return f\"\"\"\n",
    "The SQL query below is INVALID.\n",
    "\n",
    "Failure reason:\n",
    "{error_reason}\n",
    "\n",
    "Rules to fix:\n",
    "- Use schema exactly as provided\n",
    "- Follow join templates\n",
    "- Do not invent columns or tables\n",
    "- Output ONLY corrected SQL\n",
    "\n",
    "Schema:\n",
    "{schema}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Invalid SQL:\n",
    "{previous_sql}\n",
    "\n",
    "Corrected SQL:\n",
    "\"\"\".strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d15f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimized_sql_agent(\n",
    "    question: str,\n",
    "    max_retries: int = 2\n",
    ") -> Tuple[bool, str]:\n",
    "\n",
    "    raw_sql = generate_sql_optimized(question)\n",
    "    sql = preprocess_sql(raw_sql)\n",
    "    sql = normalize_sql(sql)\n",
    "\n",
    "    is_valid, reason = validate_sql(sql)\n",
    "    if is_valid:\n",
    "        return True, sql\n",
    "\n",
    "    for _ in range(max_retries):\n",
    "        correction_prompt = build_optimized_correction_prompt(\n",
    "            question,\n",
    "            schema_context,\n",
    "            cleaned_sql,\n",
    "            reason\n",
    "        )\n",
    "\n",
    "        corrected_sql = call_llm(correction_prompt)\n",
    "        sql = preprocess_sql(corrected_sql)\n",
    "        sql = normalize_sql(sql)\n",
    "\n",
    "        is_valid, reason = validate_sql(sql)\n",
    "        if is_valid:\n",
    "            return True, sql\n",
    "\n",
    "    return False, reason\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d977c1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final SQL:\n",
      "select p.product_id, p.product_name, sum(op.reordered) as total_reorders from order_products_prior op inner join products p on op.product_id = p.product_id group by p.product_id, p.product_name order by total_reorders desc limit 10;\n"
     ]
    }
   ],
   "source": [
    "question = \"Which products are most frequently reordered? give top 10\"\n",
    "\n",
    "success, result = optimized_sql_agent(question)\n",
    "\n",
    "if success:\n",
    "    print(\"Final SQL:\")\n",
    "    print(result)\n",
    "else:\n",
    "    print(\"Failed:\")\n",
    "    print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text-to-sql-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
